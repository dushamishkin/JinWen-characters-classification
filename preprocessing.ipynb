{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074be116-4bbf-4805-983a-4b55fe3f1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image, ImageOps\n",
    "import albumentations as A\n",
    "from albumentations import Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c0d9e5-b41e-4676-8f03-7181b2ad74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_pil_alpha_to_color(image, color=(255, 255, 255)):\n",
    "    \"\"\"Alpha composite an RGBA Image with a specified color.\n",
    "    Source: http://stackoverflow.com/a/9459208/284318\n",
    "    \"\"\"\n",
    "    image.load()  # needed for split()\n",
    "    background = Image.new('RGB', image.size, color)\n",
    "    background.paste(image, mask=image.split()[3])  # 3 is the alpha channel\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8331b0f-e4c9-40ba-a570-4daaad17cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gauss(image):\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "    _, img = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f76cb8-ae83-4ae0-bbfa-fd3fdbb9bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_squares(image, kernel_length):\n",
    "    \"\"\"\n",
    "    Binarizes image, keeping only vertical and horizontal lines\n",
    "    hopefully, it'll help us detect squares\n",
    "    Args:\n",
    "        image: image (cropped around circonstances)\n",
    "        kernel_length: length of kernel to use. Too long and you will catch everything,\n",
    "            too short and you catch nothing\n",
    "    Returns:\n",
    "        image binarized and keeping only vertical and horizozntal lines\n",
    "    \"\"\"\n",
    "    # thresholds image : anything beneath a certain value is set to zero\n",
    "    (thresh, img_bin) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "    # A vertical kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    vertical_ksize = (1, kernel_length)\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    verticle_lines_img = extract_lines(img_bin, vertical_ksize)\n",
    "\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    horizontal_ksize = (kernel_length, 1)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    horizontal_lines_img = extract_lines(img_bin, horizontal_ksize)\n",
    "    img_final_bin = add_lines_together(verticle_lines_img, horizontal_lines_img)\n",
    "\n",
    "    return img_final_bin\n",
    "\n",
    "\n",
    "def extract_lines(image, ksize):\n",
    "    \"\"\"\n",
    "    extract lines (horizontal or vertical, depending on ksize)\n",
    "    Args:\n",
    "        image: binarized image\n",
    "        ksize: size of kernel to use. Possible values :\n",
    "            horizontal_ksize = (kernel_length, 1)\n",
    "            vertical_ksize = (1, kernel_length)\n",
    "    Returns:\n",
    "        lines from image (vertical or horizontal, depending on ksize)\n",
    "    \"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, ksize)\n",
    "    img_temp = cv2.erode(image, kernel, iterations=3)\n",
    "    lines_img = cv2.dilate(img_temp, kernel, iterations=3)\n",
    "    return lines_img\n",
    "\n",
    "\n",
    "def add_lines_together(verticle_lines_img, horizontal_lines_img, alpha=0.5, beta=0.5):\n",
    "    \"\"\"\n",
    "    extract lines (horizontal or vertical, depending on ksize)\n",
    "    Args:\n",
    "        verticle_lines_img: image with vertical lines\n",
    "        horizontal_lines_img: image with horizontal lines\n",
    "        alpha : weight of first image. Keep at 0.5 for balance\n",
    "        beta : weight of second image. Keep at 0.5 for balance\n",
    "            alpha and beta are weighting parameters, this will\n",
    "            decide the quantity of an image to be added to make a new image\n",
    "    Returns:\n",
    "        image with an addition of both vertical and horizontal lines\n",
    "    \"\"\"\n",
    "\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    # A kernel of (3 X 3) nes.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    # erodes boundaries of features, gets rid of some noise\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    # further kill noise by thresholding\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    return img_final_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9453595-4d96-4015-a511-781252c6092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_borders(image):\n",
    "    # extract horizontal and vertical lines\n",
    "    only_box = extract_all_squares(image, kernel_length=50)\n",
    "    # build up a mask of the same size as the image\n",
    "    mask = np.zeros(image.shape, dtype='uint8')\n",
    "    # get contours of horizontal and vetical lines\n",
    "    contours, hierarchy = cv2.findContours(only_box, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # draw contours on mask\n",
    "    mask = cv2.drawContours(mask, contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "    # threhold mask and image\n",
    "    ret, mask = cv2.threshold(mask, 20, 255, cv2.THRESH_BINARY)\n",
    "    ret, box = cv2.threshold(image, 20, 255, cv2.THRESH_BINARY)\n",
    "    # remove the bits we don't want\n",
    "    box[mask == 0] = 255\n",
    "    return box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5279c94a-e9fe-41c9-9a6d-cc603ce222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_too_black(image, thresh):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image - PIL image\n",
    "        thresh - threshold\n",
    "    Returns:\n",
    "        image if threshold is not exceeded\n",
    "        else None\n",
    "    \"\"\"\n",
    "    \n",
    "    pixels = image.getdata()\n",
    "    nblack = 0\n",
    "    for pixel in pixels:\n",
    "        if pixel[0] < thresh:\n",
    "            nblack += 1\n",
    "    n = len(pixels)\n",
    "\n",
    "    if (nblack / float(n)) > 0.37:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ac9382-c94d-4b63-992f-d4977087e5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Misha\\anaconda3\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1149: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# adds fog, blur, noise, changes brightness and contrast (all at random)\n",
    "transformer_fogger = A.Compose([\n",
    "    A.augmentations.transforms.RandomFog(fog_coef_lower=0.3, fog_coef_upper=0.5, alpha_coef=0.7, p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.6),\n",
    "    Blur(blur_limit=3, p=0.3),\n",
    "    A.augmentations.transforms.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, p=0.4)\n",
    "])\n",
    "\n",
    "# adds snow, blur, noise, changes brightness and contrast (all at random)\n",
    "transformer_snower = A.Compose([\n",
    "    A.augmentations.transforms.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.6, brightness_coeff=1.5, p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.6),\n",
    "    Blur(blur_limit=3, p=0.3),\n",
    "    A.augmentations.transforms.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, p=0.4)\n",
    "])\n",
    "\n",
    "# adds blur, noise, changes brightness, rotates and scales image (all at random)\n",
    "transformer_rotater = A.Compose([\n",
    "    A.augmentations.geometric.rotate.Rotate(limit=[-30, 30], p=1),\n",
    "    A.augmentations.geometric.resize.RandomScale(0.3, p=1),\n",
    "    Blur(blur_limit=3, p=0.3),\n",
    "    A.augmentations.transforms.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, p=0.4),\n",
    "    A.augmentations.transforms.RandomBrightness(limit=0.4, p=0.5)\n",
    "])\n",
    "\n",
    "# adds blur, noise, changes brightness and applies geometric transform (all at random)\n",
    "transformer_affine = A.Compose([\n",
    "    A.augmentations.geometric.transforms.Affine(p=1),\n",
    "    Blur(blur_limit=3, p=0.3),\n",
    "    A.augmentations.transforms.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, p=0.4),\n",
    "    A.augmentations.transforms.RandomBrightness(limit=0.4, p=0.7)\n",
    "])\n",
    "\n",
    "# adds blur, noise, changes brightness and perspective (all at random)\n",
    "transformer_perspective = A.Compose([\n",
    "    A.augmentations.geometric.transforms.Perspective(p=1),\n",
    "    Blur(blur_limit=3, p=0.3),\n",
    "    A.augmentations.transforms.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, p=0.4),\n",
    "    A.augmentations.transforms.RandomBrightness(limit=0.4, p=0.7)\n",
    "])\n",
    "\n",
    "\n",
    "def create_augment_block(transformer, img):\n",
    "    thresh = transformer(image=img)\n",
    "    image_transformed = thresh[\"image\"]\n",
    "    return image_transformed\n",
    "\n",
    "def augment(img, filename):\n",
    "    for i in range(7):\n",
    "        # block 1\n",
    "        plt.imsave(f\"{filename}_{str(i)}.jpg\", create_augment_block(transformer_fogger, img))\n",
    "\n",
    "        # block 2\n",
    "        plt.imsave(f\"{filename}_{str(i + 8)}.jpg\", create_augment_block(transformer_perspective, img))\n",
    "\n",
    "        # block 3\n",
    "        plt.imsave(f\"{filename}_{str(i + 16)}.jpg\", create_augment_block(transformer_rotater, img))\n",
    "\n",
    "        # block 4\n",
    "        plt.imsave(f\"{filename}_{str(i + 24)}.jpg\", create_augment_block(transformer_affine, img))\n",
    "\n",
    "        # block 5\n",
    "        # plt.imsave(f\"{filename}_{str(i + 32)}.png\", create_augment_block(transformer_snower, img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c765317d-e6df-49e4-bb87-da3c69875c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_folder(raw_path, result_path):\n",
    "    labels_count = {}\n",
    "    for name in tqdm(glob.glob(raw_path+'/*'+'/*.png')):\n",
    "        os.chdir(result_path)\n",
    "        label = name.rpartition('_')[0]\n",
    "        _, label = os.path.split(label)\n",
    "        if label not in labels_count.keys():\n",
    "            labels_count[label] = 1\n",
    "            os.mkdir(label)\n",
    "        else:\n",
    "            labels_count[label] += 1\n",
    "        filename = f'{label}_{labels_count[label]}'\n",
    "\n",
    "        img = Image.open(name)\n",
    "        if img.size == (41, 40):\n",
    "            continue\n",
    "        img = pure_pil_alpha_to_color(img)\n",
    "        if is_too_black(img, 50):\n",
    "            img_inv = ImageOps.invert(img)\n",
    "            img_cv2 = np.array(img_inv)\n",
    "            img_gauss = apply_gauss(img_cv2)\n",
    "            img_final = crop_borders(img_gauss)\n",
    "        else:\n",
    "            img_final = np.array(img)\n",
    "            #img_final = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            \n",
    "        os.chdir(f'{result_path}/{label}')\n",
    "        augment(cv2.cvtColor(img_final, cv2.COLOR_BGR2RGB), filename)\n",
    "        #augment(img_final, filename)\n",
    "        #cv2.imwrite(filename, img_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2773bd13-eee5-4697-8b80-837c78ab4318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffea6b73eaa47c7afbc2057550ffdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_folder('C:/Users/Misha/JinWen/Raw', 'C:/Users/Misha/JinWen/Preprocessed_A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
